<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yingji Zhong</title>

    <meta name="author" content="Yingji Zhong">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yingji Zhong
                </p>
                <p>
    I'm currently a Ph.D. candidate in <a href="https://www.danxurgb.net/">Prof. Dan Xu</a>'s Vision Group at <a href="https://hkust.edu.hk/">HKUST</a>. I received my Master's Degree in 
    <a href="https://english.pku.edu.cn">Peking University</a>, where I was advised by <a href="https://www.pkuvmc.com/">Prof. Shiliang Zhang</a>. 
    I am interested in novel view synthesis, 3D reconstruction, and generation. Recently, I have been studying how to embed 3D consistency in world models. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:zzhongyj@gmail.com">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="mailto:yzhongbn@connect.ust.hk">Email2</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/zhongyingji/">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/zhongyingji/">Github</a>
                </p>
              </td>
              <td style="padding:3%;width:22%;max-width:22%">
                <a href="images/yingjizhong.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/yingjizhong.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td style="padding:8px;width:35%;vertical-align:middle;text-align:center">
        <img src="images/empower-sparse.png" alt="empower-sparse">
      </td>
      <td style="padding:8px;width:65%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2503.02230">
          <span class="papertitle">Empowering Sparse-Input Neural Radiance Fields with Dual-Level Semantic Guidance from Dense Novel Views</span>
        </a>
        <br>
        <strong>Yingji Zhong</strong>,
        Kaichen Zhou,
        Zhihao Li,
        Lanqing Hong,
        Zhenguo Li,
        Dan Xu
        <br>
        <em>AAAI</em>, 2026 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://arxiv.org/abs/2503.02230">paper</a>
        <p></p>
        <p>
    A self-improvement pipeline that leverages semantic guidance from a teacher radiance field to regularize a student radiance field for sparse-input novel view synthesis.  
        </p>
      </td>
    </tr>
	
    <tr>
      <td style="padding:8px;width:35%;vertical-align:middle;text-align:center">
        <img src="images/coadapt-sparse.png" alt="coadapt-sparse">
      </td>
      <td style="padding:8px;width:65%;vertical-align:middle">
        <a href="https://chenkangjie1123.github.io/Co-Adaptation-3DGS/">
          <span class="papertitle">Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting</span>
        </a>
        <br>
        Kangjie Chen,
        <strong>Yingji Zhong,</strong>
        Zhihao Li,
        Jiaqi Lin,
        Youyu Chen,
        Minghan Qin,
        Haoqian Wang
        <br>
        <em>NeurIPS</em>, 2025
        <br>
        <a href="https://chenkangjie1123.github.io/Co-Adaptation-3DGS/">project page</a>
        /
        <a href="https://arxiv.org/abs/2508.12720">paper</a>
        /
        <a href="https://github.com/chenkangjie1123/Co-Adaptation-of-3DGS">code</a>
        <p></p>
        <p>
    Introduce a co-adapation metric to interprete the rendering artifacts in sparse-input 3DGS. 
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:8px;width:35%;vertical-align:middle;text-align:center">
        <img src="images/taming-sparse.png" alt="taming-sparse">
      </td>
      <td style="padding:8px;width:65%;vertical-align:middle">
        <a href="https://zhongyingji.github.io/guidevd-3dgs/">
			<span class="papertitle">Taming Video Diffusion Prior with Scene-Grounding Guidance for 3D Gaussian Splatting from Sparse Inputs
</span>
        </a>
        <br>
				<strong>Yingji Zhong</strong>,
				Zhihao Li,
				Dave Zhenyu Chen,
        Lanqing Hong,
        Dan Xu
				<br>
        <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Highlight)</strong></font>
        <br>
        <a href="https://zhongyingji.github.io/guidevd-3dgs/">project page</a>
        /
        <a href="https://arxiv.org/abs/2503.05082">paper</a>
        /
        <a href="https://github.com/zhongyingji/guidedvd-3dgs">code</a>
        <p></p>
        <p>
          Taming a video diffusion model to generate more consistent sequences to address extrapolation and occlusion issues in sparse-input 3DGS. 
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:8px;width:35%;vertical-align:middle;text-align:center">
        <img src="images/cvt-sparse.png" alt="cvt-sparse">
      </td>
      <td style="padding:8px;width:65%;vertical-align:middle">
        <a href="https://zhongyingji.github.io/CVT-xRF/">
			<span class="papertitle">CVT-xRF: Contrastive In-Voxel Transformer for 3D Consistent Radiance Fields from Sparse Inputs
</span>
        </a>
        <br>
				<strong>Yingji Zhong</strong>,
				Lanqing Hong,
				Zhenguo Li,
				Dan Xu
        <br>
        <em>CVPR</em>, 2024
        <br>
        <a href="https://zhongyingji.github.io/CVT-xRF/">project page</a>
        /
        <a href="https://arxiv.org/abs/2403.16885">paper</a>
        /
        <a href="https://github.com/zhongyingji/CVT-xRF">code</a>
        <p></p>
        <p>
				Improve the sparse-input neural fields performance by field consistency regularization implemented by contrastive in-voxel Transformer.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:8px;width:35%;vertical-align:middle;text-align:center">
        <img src="images/pfe.png" alt="pfe">
      </td>
      <td style="padding:8px;width:65%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2004.09329">
			<span class="papertitle">Progressive Feature Enhancement for Person Re-Identification
</span>
        </a>
        <br>
				<strong>Yingji Zhong</strong>,
				Yaowei Wang,
				Shiliang Zhang
        <br>
        <em>IEEE Transactions on Image Processing (TIP)</em>, 2021
        <br>
        <a href="https://arxiv.org/abs/2004.09329">paper</a>
        <p></p>
        <p>
				Improve the feature robustness by merging multi-scale feature which is supervised by layer-specific supervision. </p>
      </td>
    </tr>

     <tr>
      <td style="padding:8px;width:35%;vertical-align:middle;text-align:center">
        <img src="images/apnet.png" alt="apnet">
      </td>
      <td style="padding:8px;width:65%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2004.09329">
			<span class="papertitle">Robust Partial Matching for Person Search in the Wild
</span>
        </a>
        <br>
				<strong>Yingji Zhong</strong>,
				Xiaoyu Wang,
				Shiliang Zhang
        <br>
        <em>CVPR</em>, 2020
        <br>
        <a href="https://arxiv.org/abs/2004.09329">paper</a>
        /
        <a href="https://github.com/zhongyingji/APNet">code</a>
        <p></p>
        <p>
				Address the matching failure caused by misaligned person boxes by leveraging a partial matching technique. 
        </p>
      </td>
    </tr>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody><tr>
          <td style="padding:0px">
            <br>
            <p style="text-align:center;font-size:small;">
              Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
            </p>
          </td>
        </tr>
      </tbody></table>

  </body>
</html>
